{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFLwbcd8Gt1f"
      },
      "source": [
        "# EBAC - Regressão II - regressão múltipla\n",
        "\n",
        "## Tarefa I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxDVHJxxGt1i"
      },
      "source": [
        "#### Previsão de renda II\n",
        "\n",
        "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
        "\n",
        "|variavel|descrição|\n",
        "|-|-|\n",
        "|data_ref                | Data de referência de coleta das variáveis |\n",
        "|index                   | Código de identificação do cliente|\n",
        "|sexo                    | Sexo do cliente|\n",
        "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
        "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
        "|qtd_filhos              | Quantidade de filhos do cliente|\n",
        "|tipo_renda              | Tipo de renda do cliente|\n",
        "|educacao                | Grau de instrução do cliente|\n",
        "|estado_civil            | Estado civil do cliente|\n",
        "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
        "|idade                   | Idade do cliente|\n",
        "|tempo_emprego           | Tempo no emprego atual|\n",
        "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
        "|renda                   | Renda em reais|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "RZMIYwaGGt1i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import Lasso\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "NRp58rFWGt1j"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('previsao_de_renda.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_XRkYc6Gt1k",
        "outputId": "847b6d91-1cb0-406d-ed08-b8a3d8c46997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15000 entries, 0 to 14999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Unnamed: 0             15000 non-null  int64  \n",
            " 1   data_ref               15000 non-null  object \n",
            " 2   id_cliente             15000 non-null  int64  \n",
            " 3   sexo                   15000 non-null  object \n",
            " 4   posse_de_veiculo       15000 non-null  bool   \n",
            " 5   posse_de_imovel        15000 non-null  bool   \n",
            " 6   qtd_filhos             15000 non-null  int64  \n",
            " 7   tipo_renda             15000 non-null  object \n",
            " 8   educacao               15000 non-null  object \n",
            " 9   estado_civil           15000 non-null  object \n",
            " 10  tipo_residencia        15000 non-null  object \n",
            " 11  idade                  15000 non-null  int64  \n",
            " 12  tempo_emprego          12427 non-null  float64\n",
            " 13  qt_pessoas_residencia  15000 non-null  float64\n",
            " 14  renda                  15000 non-null  float64\n",
            "dtypes: bool(2), float64(3), int64(4), object(6)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADJM_PXiGt1k"
      },
      "source": [
        "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
        "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
        "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
        "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
        "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
        "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
        "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover colunas não relevantes\n",
        "df = df.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente'])\n",
        "\n",
        "# Preenchimento de valores ausentes (ex: média do tempo_emprego)\n",
        "df['tempo_emprego'] = df['tempo_emprego'].fillna(df['tempo_emprego'].mean())\n",
        "\n",
        "# Variável resposta\n",
        "y = df['renda']\n",
        "\n",
        "# Selecionar as variáveis preditoras (excluindo a renda)\n",
        "X = df.drop(columns=['renda'])\n",
        "\n",
        "# Converter variáveis categóricas em dummy (drop_first evita multicolinearidade)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Divisão em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Escalonar as variáveis\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "VeffLo4rWAfC"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "ridge_results = {}\n",
        "\n",
        "print(\"Ridge Regression:\")\n",
        "for a in alphas:\n",
        "    ridge = Ridge(alpha=a)\n",
        "    ridge.fit(X_train_scaled, y_train)\n",
        "    y_pred = ridge.predict(X_test_scaled)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    ridge_results[a] = r2\n",
        "    print(f\"Alpha: {a:>5} | R²: {r2:.4f}\")\n",
        "\n",
        "# Identificar o melhor alpha\n",
        "best_alpha_ridge = max(ridge_results, key=ridge_results.get)\n",
        "print(f\"\\nMelhor modelo Ridge: alpha = {best_alpha_ridge} com R² = {ridge_results[best_alpha_ridge]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGc4GTK9WUTa",
        "outputId": "8dd7da8d-7a55-4682-f21e-a1490885487e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression:\n",
            "Alpha:     0 | R²: 0.2691\n",
            "Alpha: 0.001 | R²: 0.2691\n",
            "Alpha: 0.005 | R²: 0.2691\n",
            "Alpha:  0.01 | R²: 0.2691\n",
            "Alpha:  0.05 | R²: 0.2691\n",
            "Alpha:   0.1 | R²: 0.2691\n",
            "\n",
            "Melhor modelo Ridge: alpha = 0 com R² = 0.2691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_results = {}\n",
        "\n",
        "print(\"\\nLasso Regression:\")\n",
        "for a in alphas:\n",
        "    # Aumenta o número de iterações para garantir a convergência\n",
        "    lasso = Lasso(alpha=a, max_iter=10000)\n",
        "    lasso.fit(X_train_scaled, y_train)\n",
        "    y_pred = lasso.predict(X_test_scaled)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    lasso_results[a] = r2\n",
        "    print(f\"Alpha: {a:>5} | R²: {r2:.4f}\")\n",
        "\n",
        "# Identificar o melhor alpha para Lasso\n",
        "best_alpha_lasso = max(lasso_results, key=lasso_results.get)\n",
        "print(f\"\\nMelhor modelo LASSO: alpha = {best_alpha_lasso} com R² = {lasso_results[best_alpha_lasso]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBW4WXcpWZQy",
        "outputId": "e0518cfb-ddac-4ada-bd39-564488ab68ef"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lasso Regression:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.858e+11, tolerance: 7.723e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha:     0 | R²: 0.2691\n",
            "Alpha: 0.001 | R²: 0.2691\n",
            "Alpha: 0.005 | R²: 0.2691\n",
            "Alpha:  0.01 | R²: 0.2691\n",
            "Alpha:  0.05 | R²: 0.2691\n",
            "Alpha:   0.1 | R²: 0.2691\n",
            "\n",
            "Melhor modelo LASSO: alpha = 0 com R² = 0.2691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reset_index(drop=True)\n",
        "def stepwise_selection(X, y,\n",
        "                       initial_list=[],\n",
        "                       threshold_in=0.01,\n",
        "                       threshold_out=0.05,\n",
        "                       verbose=True):\n",
        "    \"\"\"Realiza seleção de variáveis por procedimento stepwise.\"\"\"\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        # Etapa de inclusão\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded, dtype=float)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(X[included + [new_column]])).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Adicionando: {best_feature:30} p-valor: {best_pval:.6f}')\n",
        "        # Etapa de exclusão\n",
        "        model = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
        "        # Exclui a constante\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()\n",
        "        if worst_pval > threshold_out:\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Removendo: {worst_feature:30} p-valor: {worst_pval:.6f}')\n",
        "        if not changed:\n",
        "            break\n",
        "    return included\n",
        "\n",
        "# Convertendo os arrays escalonados para DataFrame com os nomes das colunas\n",
        "X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "\n",
        "print(\"\\nStepwise Selection:\")\n",
        "selected_features = stepwise_selection(X_train_df, y_train, verbose=True)\n",
        "print(\"Variáveis selecionadas:\", selected_features)\n",
        "\n",
        "# Ajustando o modelo com as variáveis selecionadas\n",
        "X_train_step = X_train_df[selected_features]\n",
        "X_test_df = pd.DataFrame(X_test_scaled, columns=X_train.columns)\n",
        "X_test_step = X_test_df[selected_features]\n",
        "\n",
        "model_step = sm.OLS(y_train, sm.add_constant(X_train_step)).fit()\n",
        "y_pred_step = model_step.predict(sm.add_constant(X_test_step))\n",
        "r2_step = r2_score(y_test, y_pred_step)\n",
        "print(f\"R² do modelo Stepwise: {r2_step:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN-o6M0nWnz5",
        "outputId": "a0b49b23-5d07-4909-8551-a87e438cb480"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stepwise Selection:\n",
            "Adicionando: tempo_emprego                  p-valor: 0.000000\n",
            "Adicionando: sexo_M                         p-valor: 0.000000\n",
            "Adicionando: tipo_renda_Empresário          p-valor: 0.000000\n",
            "Adicionando: educacao_Superior completo     p-valor: 0.000002\n",
            "Adicionando: tipo_renda_Pensionista         p-valor: 0.000040\n",
            "Adicionando: idade                          p-valor: 0.000003\n",
            "Variáveis selecionadas: ['tempo_emprego', 'sexo_M', 'tipo_renda_Empresário', 'educacao_Superior completo', 'tipo_renda_Pensionista', 'idade']\n",
            "R² do modelo Stepwise: 0.2683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de um novo recurso: quadrado da idade\n",
        "X_train_quad = pd.DataFrame(X_train, copy=True)\n",
        "X_test_quad = pd.DataFrame(X_test, copy=True)\n",
        "\n",
        "X_train_quad['idade2'] = X_train_quad['idade'] ** 2\n",
        "X_test_quad['idade2'] = X_test_quad['idade'] ** 2\n",
        "\n",
        "# Converter novamente as variáveis categóricas\n",
        "X_train_quad = pd.get_dummies(X_train_quad, drop_first=True)\n",
        "X_test_quad = pd.get_dummies(X_test_quad, drop_first=True)\n",
        "\n",
        "# Garantir que as colunas sejam iguais nos dois conjuntos\n",
        "X_train_quad, X_test_quad = X_train_quad.align(X_test_quad, join='inner', axis=1)\n",
        "\n",
        "# Escalonar os dados\n",
        "scaler2 = StandardScaler()\n",
        "X_train_quad_scaled = scaler2.fit_transform(X_train_quad)\n",
        "X_test_quad_scaled = scaler2.transform(X_test_quad)\n",
        "\n",
        "# Ajustar, por exemplo, um modelo Ridge com a nova base\n",
        "ridge_improved = Ridge(alpha=0.005)\n",
        "ridge_improved.fit(X_train_quad_scaled, y_train)\n",
        "y_pred_improved = ridge_improved.predict(X_test_quad_scaled)\n",
        "r2_improved = r2_score(y_test, y_pred_improved)\n",
        "print(f\"\\nRidge com termo quadrático: R² = {r2_improved:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJaLa1NvXphX",
        "outputId": "3c3cafd5-2f89-4f7c-e817-3f979dc70b92"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ridge com termo quadrático: R² = 0.2698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando os dados originais (sem escalonamento, pois árvores não exigem)\n",
        "tree = DecisionTreeRegressor(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "r2_tree = r2_score(y_test, y_pred_tree)\n",
        "print(f\"\\nÁrvore de Regressão: R² = {r2_tree:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLehSSuMXuXh",
        "outputId": "c15e6482-d656-4679-c025-f85e00e694dd"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Árvore de Regressão: R² = 0.2940\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}